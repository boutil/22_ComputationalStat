{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=darkcyan> Variational inference </font>\n",
    "#### <font color=darkorange> Basics: Evidence Lower Bound (ELBO) & Coordinate Ascent Variational Inference (CAVI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "Required packages\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère tout d'abord le cas d'étude de l'article : ``Variational Inference: A Review for Statisticians, Blei et al; (2017)``, un mélange de gaussiennes de variance 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mélange de gaussiennes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère un mélange de $K$ gaussiennes de moyennes $\\mu = (\\mu_k)_{1\\leqslant k \\leqslant K}$ et de variance 1. Les variables $\\mu = (\\mu_k)_{1\\leqslant k \\leqslant K}$ sont (i.i.d.) de loi  gaussienne de moyenne 0 et de variance $\\sigma^2$. Le poids de la composante $k$ est noté $\\omega_k$. Conditionnellement à $\\mu$, les observations $(X_i)_{1\\leqslant i\\leqslant n}$ sont i.i.d. et la densité de probabilité de $X_1$ est:\n",
    "\n",
    "$$\n",
    "p(x|\\mu) = \\sum_{k=1}^K \\omega_k \\varphi_{\\mu_k,1}(x)\\,,\n",
    "$$\n",
    "\n",
    "où $\\varphi_{\\mu_k,\\sigma^2}$ est la densité gaussienne de moyenne $\\mu_k$ et de variance $\\sigma^2$. La vraisemblance jointe est alors :\n",
    "\n",
    "$$\n",
    "p(x_1,\\cdots,x_n) = \\int p(x_1,\\cdots,x_n|\\mu) p(\\mu) \\mathrm{d} \\mu = \\int \\prod_{i=1}^n p(x_i|\\mu) p(\\mu) \\mathrm{d} \\mu = \\int \\prod_{i=1}^n \\left(\\sum_{k=1}^K \\omega_k \\varphi_{\\mu_k,1}(x_i)\\right) p(\\mu) \\mathrm{d} \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Ecrire une fonction qui simule un échantillon de cette loi avec $K= 3$, $\\sigma^2 = 5$, $\\omega_k = 1/K$ pour tout $1\\leqslant k \\leqslant K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "K  = 3 # number of mixture components\n",
    "mu = np.random.normal(0,np.sqrt(5),3) # means of the distribution in each cluster\n",
    "n_samples = 1000 # number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre objectif est d'approcher $p(\\mu,c|x)$ où $c = (c_1,\\cdots,c_n)$ sont les composantes des observations.  L'approximation `mean-field` considérée s'écrit:\n",
    "\n",
    "$$\n",
    "q(\\mu,c) = \\prod_{k=1}^K \\varphi_{m_k,s_k}(\\mu_k)\\prod_{i=1}^n \\mathrm{Cat}_{\\phi_i}(c_i)\\,, \n",
    "$$\n",
    "\n",
    "ce qui signifie que:\n",
    "\n",
    "- $\\mu$ et $c$ sont indépendantes.\n",
    "- $(\\mu_{k})_{1\\leqslant k \\leqslant K}$ sont des gaussiennes indépendantes de moyennes $(m_{k})_{1\\leqslant k \\leqslant K}$ et variances $(s_{k})_{1\\leqslant k \\leqslant K}$.\n",
    "- $(c_{i})_{1\\leqslant i \\leqslant n}$ sont indépendantes de distribution multinomiales de paramètres $(\\phi_i)_{1\\leqslant i \\leqslant n}$: $q(c_i=k) = \\phi_i(k)$ pour $1\\leqslant k \\leqslant K$. \n",
    "\n",
    "Notons $\\mathcal{D}$ la famille des distributions où les moyennes $(m_{k})_{1\\leqslant k \\leqslant K}\\in \\mathbb{R}^K$, les variances $(s_{k})_{1\\leqslant k \\leqslant K}\\in (\\mathbb{R}_+^*)^K$ et les  $(\\phi_i)_{1\\leqslant i \\leqslant n}\\in \\mathcal{S}_K^n$ où $\\mathcal{S}_K$ est le simplexe de dimension $K$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif est de trouver le\n",
    "\"meilleur candidat\" dans $\\mathcal{D}$ pour approcher $p(\\mu,c|x)$, i.e. celui qui minimise ``la distance de Kullback suivante``:\n",
    "\n",
    "$$\n",
    "q^* = \\mathrm{Argmin}_{q\\in\\mathcal{D}} \\mathrm{KL}\\left(q(\\mu,c)\\|p(\\mu,c|x)\\right)\\,.\n",
    "$$\n",
    "\n",
    "Notez que :\n",
    "\\begin{align*}\n",
    "\\mathrm{KL}\\left(q(\\mu,c)\\|p(\\mu,c|x)\\right) &= \\mathbb{E}_q[\\log q(\\mu,c)] - \\mathbb{E}_q[\\log p(\\mu,c|x)]\\,,\\\\\n",
    " &= \\mathbb{E}_q[\\log q(\\mu,c)] - \\mathbb{E}_q[\\log p(\\mu,c,x)]+\\log p(x)\\,,\\\\\n",
    "&= -\\mathrm{ELBO}(q)+\\log p(x)\\,,\n",
    "\\end{align*}\n",
    "\n",
    "où l'``Evidence Lower Bound`` (ELBO) est\n",
    "\n",
    "$$\n",
    "\\mathrm{ELBO}(q) = -\\mathbb{E}_q[\\log q(\\mu,c)] + \\mathbb{E}_q[\\log p(\\mu,c,x)] \\,.\n",
    "$$\n",
    "\n",
    "Ainsi, ``minimiser la divergence de Kullback`` revient à maximiser la ELBO, avec $\\log p(x)\\geqslant \\mathrm{ELBO}(q)$.\n",
    "\n",
    "La complexité de $\\mathcal{D}$ détermine la complexité du problème d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic CAVI algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme CAVI calcule itérativement pour $1\\leqslant k \\leqslant K$,\n",
    "\n",
    "$$\n",
    "q(\\mu_k) \\propto \\mathrm{exp}\\left(\\mathbb{E}_{\\tilde q_{\\mu_k}}[\\log \\tilde p_k(\\mu_k|x)]\\right)\n",
    "$$\n",
    "\n",
    "et pour tout  $1\\leqslant i \\leqslant n$,\n",
    "\n",
    "$$\n",
    "q(c_i) \\propto \\mathrm{exp}\\left(\\mathbb{E}_{\\tilde q_{c_i}}[\\log \\tilde p_i(c_i|x)]\\right)\\,,\n",
    "$$\n",
    "\n",
    "où\n",
    "\n",
    "- $\\tilde p_i(c_i|x)$ est la distribution conditionnelle de $c_i$ sachant les observations et les autres paramètres et $\\tilde p_k(\\mu_k|x)$ est la loi conditionnelle de$\\mu_k$ sachant les observations et les autres paramètres.\n",
    "\n",
    "- $\\mathbb{E}_{\\tilde q_z}$ est l'espérance sous la loi variationnelle de toutes les variables sauf $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=darkorange> Application au mélange de lois gaussiennes </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Ecrire la mise à jour explicitement pour les $c_i$, $1\\leqslant i \\leqslant n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mise à jour de  $(\\phi_i)_{1\\leqslant i \\leqslant n}$ avec CAVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Ecrire une fonction effectuant la mise à jour des $c_i$, $1\\leqslant i \\leqslant n$, les autres paramètres étant fixés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAVI_update_phi(X,m,s2):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    X: data\n",
    "    m: current estimation of the m_k\n",
    "    s2: current estimation of the s_k\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    phi: new estimation of phi\n",
    "    \"\"\"\n",
    "    \n",
    "    # A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Ecrire la mise à jour explicitement pour les $(m_{k})_{1\\leqslant k \\leqslant K}$ et des $(s_{k})_{1\\leqslant k \\leqslant K}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update of $(m_{k})_{1\\leqslant k \\leqslant K}$ and $(s_{k})_{1\\leqslant k \\leqslant K}$ using CAVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "- Ecrire une fonction effectuant la mise à jour des $(m_{k})_{1\\leqslant k \\leqslant K}$ et des $(s_{k})_{1\\leqslant k \\leqslant K}$, les autres paramètres étant fixés.\n",
    "- Ecrire une fonction calculant la ELBO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAVI_update_mu_s2(X,m,phi,s2,sigma2):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    X: data\n",
    "    m: current estimation of the m_k\n",
    "    s2: current estimation of the s_k\n",
    "    phi: current estimation of phi\n",
    "    sigma2: current estimation of sigma^2\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    m, s2: new estimation of the m_k and the s_k\n",
    "    \"\"\"\n",
    "    # A compléter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elbo(X,phi,m,s2,sigma2):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    X: data\n",
    "    m: current estimation of the m_k\n",
    "    s2: current estimation of the s_k\n",
    "    phi: current estimation of phi\n",
    "    sigma2: current estimation of sigma^2\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    elbo: value of the elbo with the input parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "- Ecrire une fonction effectuant les mises à jour itératives de l'algorithme CAVI.\n",
    "- Mettre en oeuvre l'algoroithme et donner la ELBO et les estimations au fil des itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAVI_mixture_Gaussian(X,m, s2, phi, sigma2, max_iter = 500, epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    X: data\n",
    "    m: initial estimation of the m_k\n",
    "    s2: initial estimation of the s_k\n",
    "    phi: initial estimation of phi\n",
    "    sigma2: initial estimation of sigma^2\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    elbos: value of the elbo long iterations\n",
    "    m_est, s2_est: sequence of estimators along iterations\n",
    "    \"\"\"\n",
    "    \n",
    "    # A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitibilité aux conditions initiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Etudiez la sensibilité aux conditions initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
